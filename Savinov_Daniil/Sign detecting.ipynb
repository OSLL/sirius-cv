{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImgOps import *\n",
    "import copy as cp\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imreading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = cv.imread(r'query_4.jpg')\n",
    "query_img_gray = cv.cvtColor(query_img, cv.COLOR_BGR2GRAY)\n",
    "# imshow(query_img)\n",
    "\n",
    "train_img = cv.imread(r'train_4.jpg')\n",
    "train_img_gray = cv.cvtColor(train_img, cv.COLOR_BGR2GRAY)\n",
    "# imshow(train_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding keypoints via SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "query_kps, query_des = sift.detectAndCompute(query_img_gray, None)\n",
    "train_kps, train_des = sift.detectAndCompute(train_img_gray, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keypoints matching via FLANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = dict(algorithm=1, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(query_des, train_des, k=2)\n",
    "matchesMask = [[0, 0] for _ in range(len(matches))]\n",
    "\n",
    "good_matches = []\n",
    "for i, (m, n) in enumerate(matches):\n",
    "    if m.distance < .5 * n.distance:\n",
    "        matchesMask[i] = [1, 0]\n",
    "        good_matches.append(m)\n",
    "good_matches = np.asarray(good_matches)\n",
    "\n",
    "draw_params = dict(matchColor=(0, 255, 0),\n",
    "                   matchesMask=matchesMask,\n",
    "                   flags=cv.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "matched_img = cv.drawMatchesKnn(query_img, query_kps, train_img, train_kps, matches, None, **draw_params)\n",
    "\n",
    "# imshow(matched_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering via DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary(ptQuery_ptTrain) = { (x_q, y_q): (x_t), (y_t) }\n",
    "ptQuery_ptTrain = {}\n",
    "for DMatch in good_matches:\n",
    "    pt_q = query_kps[DMatch.queryIdx].pt\n",
    "    pt_t = train_kps[DMatch.trainIdx].pt\n",
    "    ptQuery_ptTrain[pt_q] = pt_t\n",
    "\n",
    "\n",
    "# Clustering\n",
    "clusterized = DBSCAN(eps=50, min_samples=5).fit_predict(list(ptQuery_ptTrain.keys()))\n",
    "\n",
    "# Dictionary(cluster_pts_q) = { cluster_name: [(x_q, y_q), ...] }\n",
    "cluster_pts_q = {}\n",
    "for gp, pt in zip(clusterized, list(ptQuery_ptTrain.keys())):\n",
    "    if gp == -1: continue\n",
    "    else:\n",
    "        if gp not in cluster_pts_q:\n",
    "            cluster_pts_q[gp] = [pt]\n",
    "        else:\n",
    "            cluster_pts_q[gp].append(pt)\n",
    "\n",
    "cluster_pts_t = cp.deepcopy(cluster_pts_q)\n",
    "for cluster in cluster_pts_t:\n",
    "    for i, pt in enumerate(cluster_pts_t[cluster]):\n",
    "        cluster_pts_t[cluster][i] = ptQuery_ptTrain[pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters' visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pts in cluster_pts_q.values():\n",
    "#     for x, y in pts:\n",
    "#         clust_img = cv.circle(query_img, (int(x), int(y)), radius=3, color=(0, 255, 0), thickness=-1)\n",
    "#     imshow(clust_img)\n",
    "#     clust_img = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in cluster_pts_q:\n",
    "    if cluster != 1:\n",
    "        src = np.float32(cluster_pts_t[cluster]).reshape(-1, 1, 2)\n",
    "        dst = np.float32(cluster_pts_q[cluster]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, _ = cv.findHomography(src, dst, cv.RANSAC, 5.)\n",
    "        h, w = train_img_gray.shape\n",
    "        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "        dst = cv.perspectiveTransform(pts, M)\n",
    "        dst = [np.int32(dst)]\n",
    "\n",
    "        res_img = cv.polylines(query_img, dst, True, (0, 0, 255), 3, cv.LINE_AA)\n",
    "        res_img = cv.putText(res_img, 'Road Sign', tuple(dst[0][0][0]), cv.FONT_HERSHEY_DUPLEX, 1, (255, 0, 255), 1, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(res_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
